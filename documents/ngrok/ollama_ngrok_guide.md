# ğŸ¤– HÆ°á»›ng dáº«n Expose Ollama qua Ngrok

## ğŸ“‹ TÃ¬nh huá»‘ng

Báº¡n cÃ³ 2 mÃ¡y:
- **MÃ¡y A (Server)**: MÃ¡y cháº¡y Ollama server (GPU máº¡nh Ä‘á»ƒ cháº¡y AI model)
- **MÃ¡y B (Docker)**: MÃ¡y cháº¡y Docker vá»›i `stock-service` cáº§n connect Ä‘áº¿n Ollama

**Má»¥c tiÃªu:** MÃ¡y B (Docker) connect Ä‘áº¿n Ollama trÃªn MÃ¡y A qua Internet (dÃ¹ng Ngrok)

---

## ğŸ¯ Architecture

```mermaid
graph LR
    A[stock-service<br/>Docker Container<br/>MÃ¡y B] -->|HTTPS| B[Ngrok Cloud]
    B -->|Forward| C[Ngrok Client<br/>MÃ¡y A]
    C -->|Port 11434| D[Ollama Server<br/>localhost:11434<br/>MÃ¡y A]
```

---

## âš™ï¸ MÃ¡y A (MÃ¡y cháº¡y Ollama Server)

### BÆ°á»›c 1: CÃ i Ä‘áº·t vÃ  khá»Ÿi Ä‘á»™ng Ollama

Download Ollama: https://ollama.com/download

Sau khi cÃ i, kiá»ƒm tra version:
```cmd
ollama --version
```

### BÆ°á»›c 2: Expose Ollama ra 0.0.0.0 (cho phÃ©p káº¿t ná»‘i tá»« bÃªn ngoÃ i)

Máº·c Ä‘á»‹nh Ollama chá»‰ listen trÃªn `127.0.0.1` (localhost only). Äá»ƒ Ngrok cÃ³ thá»ƒ forward, cáº§n expose ra `0.0.0.0`.

**TrÃªn Windows:**
```cmd
set OLLAMA_HOST=0.0.0.0:11434
ollama serve
```

> **LÆ°u Ã½:** Giá»¯ cá»­a sá»• CMD nÃ y **má»Ÿ** (Ä‘á»ƒ Ollama server cháº¡y).

**Kiá»ƒm tra:**
```cmd
# Má»Ÿ CMD má»›i
curl http://localhost:11434/api/version
```

Káº¿t quáº£ mong Ä‘á»£i:
```json
{"version":"0.1.x"}
```

### BÆ°á»›c 3: Pull model cáº§n dÃ¹ng

```cmd
ollama pull qwen2.5:7b
```

Hoáº·c model khÃ¡c tÃ¹y theo config cá»§a báº¡n.

**Xem danh sÃ¡ch model:**
```cmd
ollama list
```

### BÆ°á»›c 4: CÃ i Ä‘áº·t Ngrok trÃªn MÃ¡y A

1. Download: https://ngrok.com/download
2. ÄÄƒng kÃ½ tÃ i khoáº£n: https://dashboard.ngrok.com/signup
3. Láº¥y authtoken tá»«: https://dashboard.ngrok.com/get-started/your-authtoken

**Setup authtoken:**
```cmd
ngrok config add-authtoken YOUR_AUTHTOKEN_HERE
```

### BÆ°á»›c 5: Expose Ollama qua Ngrok

```cmd
ngrok http 11434
```

**Output:**
```
Session Status                online
Account                       your-email@gmail.com
Forwarding                    https://abc123xyz.ngrok-free.app -> http://localhost:11434

Connections                   ttl     opn     rt1     rt5     p50     p90
                              0       0       0.00    0.00    0.00    0.00
```

> [!IMPORTANT]
> **GHI Láº I URL nÃ y**: `https://abc123xyz.ngrok-free.app`
> 
> ÄÃ¢y lÃ  public URL Ä‘á»ƒ truy cáº­p Ollama tá»« Internet.

**Giá»¯ cá»­a sá»• CMD nÃ y má»Ÿ** (Ä‘á»«ng táº¯t ngrok).

### BÆ°á»›c 6: Verify Ngrok hoáº¡t Ä‘á»™ng

Tá»« **mÃ¡y khÃ¡c** (hoáº·c mÃ¡y B), test:
```cmd
curl https://abc123xyz.ngrok-free.app/api/version
```

Náº¿u tháº¥y `{"version":"0.1.x"}` â†’ **ThÃ nh cÃ´ng!** âœ…

---

## ğŸ³ MÃ¡y B (MÃ¡y cháº¡y Docker)

### BÆ°á»›c 1: Cáº­p nháº­t docker-compose.yml

Má»Ÿ file `docker-compose.yml`, tÃ¬m pháº§n `stock-service` vÃ  sá»­a:

```yaml
stock-service:
  <<: *spring-boot-common
  build: ./stock-service
  container_name: stock-service
  environment:
    # ===== THAY URL NGROK VÃ€O ÄÃ‚Y =====
    - OLLAMA_BASE_URL=https://abc123xyz.ngrok-free.app
    - OLLAMA_MODEL=qwen2.5:7b
    - SPRING_CLOUD_CONFIG_URI=http://config-server:8888
    - EUREKA_URI=http://eureka-server:8761/eureka
    # ... cÃ¡c biáº¿n khÃ¡c
```

### BÆ°á»›c 2: Restart stock-service

```cmd
cd d:\CP2496H07_GROUP1
docker-compose up -d --force-recreate stock-service
```

### BÆ°á»›c 3: Kiá»ƒm tra logs

```cmd
docker logs stock-service --tail 100 -f
```

**TÃ¬m xem cÃ³ log nÃ y:**
```
âœ… Connected to Ollama at https://abc123xyz.ngrok-free.app
```

hoáº·c error:
```
âŒ Failed to connect to Ollama: Connection refused
```

---

## âš ï¸ LÆ°u Ã½ quan trá»ng

### 1. URL Ngrok thay Ä‘á»•i má»—i láº§n restart

Ngrok Free tier cho URL **ngáº«u nhiÃªn** má»—i láº§n cháº¡y:
- Láº§n 1: `https://abc123.ngrok-free.app`
- Láº§n 2: `https://xyz789.ngrok-free.app` â† **KhÃ¡c!**

**Giáº£i phÃ¡p:** DÃ¹ng **Ngrok Static Domain** (Free)

#### Claim Static Domain (Miá»…n phÃ­)

1. ÄÄƒng nháº­p: https://dashboard.ngrok.com/
2. **Cloud Edge** â†’ **Domains**
3. Click **+ Create Domain** â†’ **Create**
4. VÃ­ dá»¥ Ä‘Æ°á»£c: `ollama-server.ngrok-free.app`

#### Cháº¡y vá»›i static domain:
```cmd
ngrok http 11434 --domain=ollama-server.ngrok-free.app
```

â†’ URL **cá»‘ Ä‘á»‹nh**, khÃ´ng thay Ä‘á»•i khi restart! âœ…

---

### 2. Performance \u0026 Latency

```
Docker â†’ Internet â†’ Ngrok Cloud (US/SG) â†’ MÃ¡y A
```

- **Latency thÃªm:** ~100-500ms
- **Throughput giáº£m:** Do bÄƒng thÃ´ng Internet

**Khuyáº¿n nghá»‹:**
- DÃ¹ng cho **demo** hoáº·c **testing**
- **KHÃ”NG dÃ¹ng production** (cháº­m + khÃ´ng á»•n Ä‘á»‹nh)

---

### 3. Bandwidth Limit (Ngrok Free)

- **1GB/thÃ¡ng**
- Ollama AI model response cÃ³ thá»ƒ lá»›n (~1-10KB/request)
- Æ¯á»›c tÃ­nh: ~100,000-1,000,000 requests/thÃ¡ng

**LÆ°u Ã½:** Náº¿u vÆ°á»£t quota â†’ Ngrok ngá»«ng hoáº¡t Ä‘á»™ng.

---

### 4. Security

> [!CAUTION]
> - Ngrok tháº¥y Ä‘Æ°á»£c **Táº¤T Cáº¢ traffic** (SSL terminated táº¡i Ngrok)
> - **KHÃ”NG gá»­i dá»¯ liá»‡u nháº¡y cáº£m** (API keys, passwords)
> - Chá»‰ dÃ¹ng cho **demo/development**

---

## ğŸ”§ Troubleshooting

### Lá»—i: Connection refused

**NguyÃªn nhÃ¢n:** Ollama khÃ´ng expose ra 0.0.0.0

**Giáº£i phÃ¡p:**
```cmd
# TrÃªn MÃ¡y A
set OLLAMA_HOST=0.0.0.0:11434
ollama serve
```

---

### Lá»—i: Model not found

**NguyÃªn nhÃ¢n:** Model chÆ°a download

**Giáº£i phÃ¡p:**
```cmd
# TrÃªn MÃ¡y A
ollama pull qwen2.5:7b
ollama list  # Verify
```

---

### Lá»—i: Ngrok tunnel not working

**NguyÃªn nhÃ¢n:** ChÆ°a authenticate

**Giáº£i phÃ¡p:**
```cmd
ngrok config add-authtoken YOUR_TOKEN
ngrok http 11434
```

---

## ğŸ“š CÃ¡c lá»‡nh cáº§n nhá»›

### MÃ¡y A (Ollama Server)

```cmd
# 1. Start Ollama (expose ra 0.0.0.0)
set OLLAMA_HOST=0.0.0.0:11434
ollama serve

# 2. Pull model (terminal má»›i)
ollama pull qwen2.5:7b

# 3. Start Ngrok (terminal má»›i)
ngrok http 11434 --domain=ollama-server.ngrok-free.app
```

### MÃ¡y B (Docker)

```yaml
# docker-compose.yml
stock-service:
  environment:
    - OLLAMA_BASE_URL=https://ollama-server.ngrok-free.app
    - OLLAMA_MODEL=qwen2.5:7b
```

```cmd
# Restart stock-service
docker-compose up -d --force-recreate stock-service

# Check logs
docker logs stock-service -f
```

---

## âœ… Checklist tá»•ng quan

**TrÃªn MÃ¡y A (Ollama Server):**
- [ ] CÃ i Ä‘áº·t Ollama
- [ ] Pull model: `ollama pull qwen2.5:7b`
- [ ] Expose Ollama: `set OLLAMA_HOST=0.0.0.0:11434` â†’ `ollama serve`
- [ ] CÃ i Ä‘áº·t Ngrok
- [ ] Authenticate Ngrok: `ngrok config add-authtoken`
- [ ] (Optional) Claim static domain
- [ ] Start Ngrok: `ngrok http 11434 --domain=your-domain.ngrok-free.app`
- [ ] Copy Ngrok URL

**TrÃªn MÃ¡y B (Docker):**
- [ ] Sá»­a `docker-compose.yml`: `OLLAMA_BASE_URL=https://your-ngrok-url.ngrok-free.app`
- [ ] Restart: `docker-compose up -d --force-recreate stock-service`
- [ ] Check logs: `docker logs stock-service -f`

---

## ğŸ¯ Alternative: LAN Direct Connection

Náº¿u 2 mÃ¡y trong cÃ¹ng máº¡ng LAN (hoáº·c VPN):

**MÃ¡y A:**
```cmd
set OLLAMA_HOST=0.0.0.0:11434
ollama serve
```

**TÃ¬m IP cá»§a MÃ¡y A:**
```cmd
ipconfig
# VÃ­ dá»¥: 192.168.1.100
```

**MÃ¡y B (docker-compose.yml):**
```yaml
stock-service:
  environment:
    - OLLAMA_BASE_URL=http://192.168.1.100:11434
```

> **LÆ°u Ã½:** CÃ¡ch nÃ y nhanh hÆ¡n Ngrok nhÆ°ng chá»‰ dÃ¹ng Ä‘Æ°á»£c trong LAN.

---

## ğŸ“ Káº¿t luáº­n

- **Ngrok + Ollama**: PhÃ¹ há»£p cho remote demo, testing tá»« xa
- **LAN Direct**: PhÃ¹ há»£p cho local development, nhanh hÆ¡n
- **Production**: NÃªn dÃ¹ng VPS/Cloud vá»›i static IP + reverse proxy

ChÃºc báº¡n thÃ nh cÃ´ng! ğŸš€
